{"version":3,"sources":["Holding IC.png","App.js","reportWebVitals.js","index.js"],"names":["videoConstraints","height","width","maxWidth","facingMode","buildDetectedObjects","scores","threshold","boxes","classes","detectionObjects","forEach","score","i","bbox","minY","minX","maxY","maxX","push","class","label","toFixed","App","webcamRef","useRef","useState","setModel","videoWidth","videoHeight","loadModel","a","tf","loadedModel","console","log","onCapture","model","current","video","readyState","cnvs","document","getElementById","ctx","getContext","font","textBaseline","rawImgTensor","fromPixels","inputTensor","transpose","expandDims","performance","now","executeAsync","then","res","detection_boxes","arraySync","detection_classes","detection_scores","dataSync","detections","clearRect","item","x","y","strokeStyle","lineWidth","strokeRect","fillStyle","textWidth","measureText","textHeight","parseInt","fillRect","fillText","len","length","finally","useEffect","_","setInterval","className","style","position","top","zIndex","id","backgroundColor","audio","ref","screenshotQuality","screenshotFormat","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode"],"mappings":"0cAAe,I,OCMTA,EAAmB,CACrBC,OAAQ,KACRC,MAAO,KACPC,SAAU,QACVC,WAAY,eAKVC,EAAuB,SAACC,EAAQC,EAAWC,EAAOC,EAASR,EAAQC,GACrE,IAAMQ,EAAmB,GAqBzB,OAnBAJ,EAAOK,SAAQ,SAACC,EAAOC,GACnB,GAAID,EAAQL,EAAW,CACnB,IAAMO,EAAO,GACPC,EAAOP,EAAM,GAAGK,GAAG,GAAKZ,EACxBe,EAAOR,EAAM,GAAGK,GAAG,GAAKX,EACxBe,EAAOT,EAAM,GAAGK,GAAG,GAAKZ,EACxBiB,EAAOV,EAAM,GAAGK,GAAG,GAAKX,EAC9BY,EAAK,GAAKE,EACVF,EAAK,GAAKC,EACVD,EAAK,GAAKI,EAAOF,EACjBF,EAAK,GAAKG,EAAOF,EACjBL,EAAiBS,KAAK,CAClBC,MAAOX,EAAQI,GACfQ,MAAO,OACPT,MAAOA,EAAMU,QAAQ,GACrBR,KAAMA,QAIXJ,GA0LIa,MAnKf,WACI,IAAMC,EAAYC,iBAAO,MACzB,EAA0BC,mBAAS,MAAnC,mBAAcC,GAAd,WACA,EAAoCD,mBAAS,KAA7C,mBAAOE,EAAP,KACA,GADA,KACsCF,mBAAS,MAA/C,mBAAOG,EAAP,KAEMC,GAFN,KAEe,uCAAG,4BAAAC,EAAA,sEAEYC,IAvDP,kCAqDL,cAERC,EAFQ,OAGdN,EAASM,GACTC,QAAQC,IAAI,iBAJE,kBAKPF,GALO,2CAAH,sDAQTG,EAAS,uCAAG,WAAOC,GAAP,6BAAAN,EAAA,sDAGmB,qBAAtBP,EAAUc,SAAiD,OAAtBd,EAAUc,SAA2D,IAAvCd,EAAUc,QAAQC,MAAMC,YAA8B,OAAVH,IAIhHE,EAAQf,EAAUc,QAAQC,MAC1BX,EAAaW,EAAMX,WACnBC,EAAcU,EAAMV,YAG1BL,EAAUc,QAAQC,MAAMrC,MAAQ0B,EAChCJ,EAAUc,QAAQC,MAAMtC,OAAS4B,GAE3BY,EAAOC,SAASC,eAAe,aAChCzC,MAAQ0B,EACba,EAAKxC,OAAS4B,EAGRe,EAAMH,EAAKI,WAAW,MAGtBC,EAAO,kBACbF,EAAIE,KAAOA,EACXF,EAAIG,aAAe,MAIbC,EAAehB,IAAWiB,WAAWV,GAQrCW,EAAclB,KAAQ,WACxB,OAAOgB,EAAaG,UAAU,CAAC,EAAG,EAAG,IAAIC,gBAG7BC,YAAYC,MAC5BjB,EACKkB,aAAaL,GACbM,MAAK,SAACC,GASH,IAAMC,EAAkBD,EAAI,GAAGE,YACzBC,EAAoBH,EAAI,GAAGE,YAC3BE,EAAmBJ,EAAI,GAAGK,WAC1BC,EAAa1D,EAAqBwD,EAAkB,GAAKH,EAAiBE,EAAmB/B,EAAaD,GA8BhH,OA7BAgB,EAAIoB,UAAU,EAAG,EAAGxC,EAAUc,QAAQC,MAAMX,WAAYJ,EAAUc,QAAQC,MAAMV,aAChFkC,EAAWpD,SAAQ,SAACsD,GAChB,IAAMC,EAAID,EAAI,KAAS,GACjBE,EAAIF,EAAI,KAAS,GACjB/D,EAAQ+D,EAAI,KAAS,GACrBhE,EAASgE,EAAI,KAAS,GAG5BrB,EAAIwB,YAAc,UAClBxB,EAAIyB,UAAY,EAChBzB,EAAI0B,WAAWJ,EAAGC,EAAGjE,EAAOD,GAG5B2C,EAAI2B,UAAY,UAChB,IAAMC,EAAY5B,EAAI6B,YAAYR,EAAI,MAAY,KAAO,IAAMA,EAAI,OAAW3C,QAAQ,GAAK,KAAKpB,MAC1FwE,EAAaC,SAAS7B,EAAM,IAClCF,EAAIgC,SAASV,EAAGC,EAAGK,EAAY,EAAGE,EAAa,MAGnDX,EAAWpD,SAAQ,SAACsD,GAChB,IAAMC,EAAID,EAAI,KAAS,GACjBE,EAAIF,EAAI,KAAS,GAGvBrB,EAAI2B,UAAY,UAChB3B,EAAIiC,SAASZ,EAAI,MAAY,KAAO,IAAMA,EAAI,OAAW3C,QAAQ,GAAK,IAAK4C,EAAGC,MAI3EV,KAEVD,MAAK,SAACC,GAGH,IAFA,IAAI5C,EAAI,EACFiE,EAAMrB,EAAIsB,OACTlE,EAAIiE,GACP9C,IAAWyB,EAAI5C,IACfA,OAGPmE,SAAQ,WACLhD,IAAWgB,GACXhB,IAAWkB,OAlGT,2CAAH,sDAgIf,OArBA+B,qBAAU,WAMNjD,MACKwB,MAAK,SAAC0B,GACHlD,MACAE,QAAQC,IAAI,oBAEfqB,KAAK1B,GACL0B,MAAK,SAACvB,GACHC,QAAQC,IAAI,wBACZgD,YAAY/C,EAAW,IAAKH,QAGrC,IAKC,sBAAKmD,UAAU,MAAf,UACI,qBAAKC,MAAO,CAAEC,SAAU,WAAYC,IAAK,MAAOC,OAAQ,QAAxD,SACI,wBAAQC,GAAG,WAAWvF,MAAO0B,EAAY3B,OAAQ4B,EAAawD,MAAO,CAAEK,gBAAiB,mBAE5F,qBAAKL,MAAO,CAAEC,SAAU,WAAYC,IAAK,OAAzC,SACI,cAAC,IAAD,CACII,OAAO,EACPF,GAAG,MACHG,IAAKpE,EAELqE,kBAAmB,EACnBC,iBAAiB,aACjB9F,iBAAkBA,UC3MvB+F,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBzC,MAAK,YAAkD,IAA/C0C,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEF/D,SAASC,eAAe,SAM1BoD,M","file":"static/js/main.2e74246c.chunk.js","sourcesContent":["export default __webpack_public_path__ + \"static/media/Holding IC.5b6eada1.png\";","import \"./App.css\";\nimport React, { useEffect, useState, useRef } from \"react\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport Webcam from \"react-webcam\";\nimport ic_img from \"./Holding IC.png\";\n\nconst videoConstraints = {\n    height: 1080,\n    width: 1920,\n    maxWidth: \"100vw\",\n    facingMode: \"environment\",\n};\n\nconst face_detection_url = \"tfjs/face_detection/model.json\";\n\nconst buildDetectedObjects = (scores, threshold, boxes, classes, height, width) => {\n    const detectionObjects = [];\n\n    scores.forEach((score, i) => {\n        if (score > threshold) {\n            const bbox = [];\n            const minY = boxes[0][i][0] * height;\n            const minX = boxes[0][i][1] * width;\n            const maxY = boxes[0][i][2] * height;\n            const maxX = boxes[0][i][3] * width;\n            bbox[0] = minX;\n            bbox[1] = minY;\n            bbox[2] = maxX - minX;\n            bbox[3] = maxY - minY;\n            detectionObjects.push({\n                class: classes[i],\n                label: \"face\",\n                score: score.toFixed(4),\n                bbox: bbox,\n            });\n        }\n    });\n    return detectionObjects;\n};\n\nconst readImageFile = (file) => {\n    return new Promise((resolve) => {\n        const reader = new FileReader();\n\n        reader.onload = () => resolve(reader.result);\n\n        reader.readAsDataURL(file);\n    });\n};\n\nconst createHTMLImageElement = (imageSrc) => {\n    return new Promise((resolve) => {\n        const img = new Image();\n\n        img.onload = () => resolve(img);\n\n        img.src = imageSrc;\n    });\n};\n\nfunction App() {\n    const webcamRef = useRef(null);\n    const [model, setModel] = useState(null);\n    const [videoWidth, setVideoWidth] = useState(960);\n    const [videoHeight, setVideoHeight] = useState(640);\n\n    const loadModel = async () => {\n        /** @type {tf.GraphModel} */\n        const loadedModel = await tf.loadGraphModel(face_detection_url);\n        setModel(loadedModel);\n        console.log(\"Model loaded.\");\n        return loadedModel;\n    };\n\n    const onCapture = async (model) => {\n        // console.log(\"Capturing\");\n        // Check data is available\n        if (typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4 && model !== null) {\n            // if (true) {\n            // Get Video Properties\n            /** @type {HTMLVideoElement} */\n            const video = webcamRef.current.video;\n            const videoWidth = video.videoWidth;\n            const videoHeight = video.videoHeight;\n\n            // Set video width\n            webcamRef.current.video.width = videoWidth;\n            webcamRef.current.video.height = videoHeight;\n\n            const cnvs = document.getElementById(\"myCanvas\");\n            cnvs.width = videoWidth;\n            cnvs.height = videoHeight;\n            // cnvs.style.position = \"absolute\";\n\n            const ctx = cnvs.getContext(\"2d\");\n\n            // Font options.\n            const font = \"16px sans-serif\";\n            ctx.font = font;\n            ctx.textBaseline = \"top\";\n\n            // const ic_img = document.getElementById(\"ic_img\");\n            /** @type {tf.Tensor3D} */\n            const rawImgTensor = tf.browser.fromPixels(video);\n            // const rawImgTensor = tf.browser.fromPixels(ic_img);\n            // console.log(`rawImgTensor shape: ${rawImgTensor.shape}`);\n\n            // const [inputTensorWidth, inputTensorHeight] = model.inputs[0].shape.slice(1, 3); // [640, 640]\n            // const inputTensor = tf.tidy(() => {\n            //     return tf.image.resizeBilinear(rawImgTensor, [inputTensorWidth, inputTensorHeight]).div(255.0).expandDims(0);\n            // });\n            const inputTensor = tf.tidy(() => {\n                return rawImgTensor.transpose([0, 1, 2]).expandDims();\n            });\n            // console.log(`inputTensor shape: ${inputTensor.shape}`);\n            let startTime = performance.now();\n            model\n                .executeAsync(inputTensor)\n                .then((res) => {\n                    // const a0 = res[0].arraySync(); // num_detection\n                    // const a1 = res[1].arraySync(); // raw_detection_boxes\n                    // const a2 = res[2].arraySync(); // detection_anchor_indices\n                    // const a3 = res[3].arraySync(); // raw_detection_scores\n                    // const a4 = res[4].arraySync(); // detection_boxes\n                    // const a5 = res[5].arraySync(); // detection_classes\n                    // const a6 = res[6].arraySync(); // detection_scores\n                    // const a7 = res[7].arraySync(); // detection_multiclass_scores\n                    const detection_boxes = res[4].arraySync();\n                    const detection_classes = res[5].arraySync();\n                    const detection_scores = res[6].dataSync();\n                    const detections = buildDetectedObjects(detection_scores, 0.5, detection_boxes, detection_classes, videoHeight, videoWidth);\n                    ctx.clearRect(0, 0, webcamRef.current.video.videoWidth, webcamRef.current.video.videoHeight);\n                    detections.forEach((item) => {\n                        const x = item[\"bbox\"][0];\n                        const y = item[\"bbox\"][1];\n                        const width = item[\"bbox\"][2];\n                        const height = item[\"bbox\"][3];\n\n                        // Draw the bounding box.\n                        ctx.strokeStyle = \"#00FFFF\";\n                        ctx.lineWidth = 4;\n                        ctx.strokeRect(x, y, width, height);\n\n                        // Draw the label background.\n                        ctx.fillStyle = \"#00FFFF\";\n                        const textWidth = ctx.measureText(item[\"label\"] + \" \" + (100 * item[\"score\"]).toFixed(2) + \"%\").width;\n                        const textHeight = parseInt(font, 10); // base 10\n                        ctx.fillRect(x, y, textWidth + 4, textHeight + 4);\n                    });\n\n                    detections.forEach((item) => {\n                        const x = item[\"bbox\"][0];\n                        const y = item[\"bbox\"][1];\n\n                        // Draw the text last to ensure it's on top.\n                        ctx.fillStyle = \"#000000\";\n                        ctx.fillText(item[\"label\"] + \" \" + (100 * item[\"score\"]).toFixed(2) + \"%\", x, y);\n                    });\n                    // let endTime = performance.now();\n                    // console.log(`Took ${endTime - startTime} milliseconds`);\n                    return res;\n                })\n                .then((res) => {\n                    let i = 0;\n                    const len = res.length;\n                    while (i < len) {\n                        tf.dispose(res[i]);\n                        i++;\n                    }\n                })\n                .finally(() => {\n                    tf.dispose(rawImgTensor);\n                    tf.dispose(inputTensor);\n                });\n            // console.dir(`numTensors: ${tf.memory().numTensors}`);\n        }\n    };\n\n    /* \n    Run only once\n     */\n    useEffect(() => {\n        // console.log(tfgl.version_webgl);\n        // console.log(tf.getBackend());\n        // tfgl.webgl.forceHalfFloat();\n        // var maxSize = tfgl.webgl_util.getWebGLMaxTextureSize(tfgl.version_webgl);\n        // console.log(maxSize);\n        tf.ready()\n            .then((_) => {\n                tf.enableProdMode();\n                console.log(\"tfjs is ready\");\n            })\n            .then(loadModel)\n            .then((loadedModel) => {\n                console.log(\"Test model is loaded\");\n                setInterval(onCapture, 100, loadedModel);\n                // onCapture(loadedModel);\n            });\n    }, []);\n\n    // let supportedConstraints = navigator.mediaDevices.getSupportedConstraints();\n    // console.log(supportedConstraints);\n    return (\n        <div className=\"App\">\n            <div style={{ position: \"absolute\", top: \"0px\", zIndex: \"9999\" }}>\n                <canvas id=\"myCanvas\" width={videoWidth} height={videoHeight} style={{ backgroundColor: \"transparent\" }} />\n            </div>\n            <div style={{ position: \"absolute\", top: \"0px\" }}>\n                <Webcam\n                    audio={false}\n                    id=\"img\"\n                    ref={webcamRef}\n                    // width={640}\n                    screenshotQuality={1}\n                    screenshotFormat=\"image/jpeg\"\n                    videoConstraints={videoConstraints}\n                />\n                {/* <img id=\"ic_img\" src={ic_img} alt=\"\" /> */}\n            </div>\n        </div>\n    );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}